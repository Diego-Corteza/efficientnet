{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x_data, y_data, test_percent=0.20, seed=42):\n",
    "        \"\"\"\n",
    "        The method split_data(), which belongs to the class Model, receives four parameters:\n",
    "\n",
    "        - x_data: Samples (torch.Tensor).\n",
    "        - y_data: Targets of the samples (torch.Tensor).\n",
    "        - test_percent: Percentage of total data employed for testing (default = 0.20).\n",
    "        - seed:         Used to replicate the resulting training and evaluation sets (default = None).\n",
    "\n",
    "        And it is going to return two sets one for training and one for testing (each of which contains is divided into samples and targets).\n",
    "        \"\"\"\n",
    "\n",
    "        x_numpy = x_data.cpu().numpy()\n",
    "        y_numpy = y_data.cpu().numpy()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_percent, random_state=seed)\n",
    "        \n",
    "        return torch.from_numpy(X_train).float().cuda(), torch.from_numpy(X_test).float().cuda(), torch.from_numpy(y_train).long().cuda(), torch.from_numpy(y_test).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56000, 784])\n",
      "torch.Size([56000])\n",
      "torch.Size([14000, 784])\n",
      "torch.Size([14000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_t = torch.from_numpy(X).float().cuda()\n",
    "Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f72c5bbf8e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_sample = 850\n",
    "\n",
    "sample = X_train[num_sample].cpu().numpy()\n",
    "target = y_train[num_sample].cpu().numpy()\n",
    "\n",
    "print('Target: {}'.format(target))\n",
    "\n",
    "img = Image.fromarray(sample.reshape(28,28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_data, y_data):\n",
    "        \"\"\"\n",
    "        This method receives a set of samples (x_data), with their respective targets (y_data), and gets the accuracy of the model.\n",
    "        \"\"\"\n",
    "\n",
    "        num_correct = 0\n",
    "        num_samples = len(y_data)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_sample, y_sample in zip(x_data, y_data):\n",
    "                \n",
    "                scores = model(x_sample)\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == y_sample).sum()\n",
    "            \n",
    "            return (num_correct/num_samples)*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.efficientnet_b0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [56000, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/franz/Desktop/EfficientNet Project/efficientnet/trining_u_tests.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000010?line=0'>1</a>\u001b[0m model(X_train)\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py:267\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=265'>266</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=266'>267</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py:257\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=255'>256</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=256'>257</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=258'>259</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=259'>260</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///home/franz/v_environments/hello_environments/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [56000, 784]"
     ]
    }
   ],
   "source": [
    "model(X_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707c54fc449c242a99d0015019b0ebb80e91ba051eefcf42ec4fa5bd006a7811"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hello_environments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
