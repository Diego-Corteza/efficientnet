{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\n",
    "    \"\"\"\n",
    "    The class 'train_model', which inherits from the class 'Model', is initialized with a dictionary that contains some parameters for the training:\n",
    "\n",
    "    - lr:         Learning rate (default = 0.001).\n",
    "    - epochs:     Number of epochs to train (default = 100).\n",
    "    - MAX_EPOCHS: Max number of epochs allowed (default = 1000).\n",
    "\n",
    "    And contains six methods:\n",
    "\n",
    "    - train\n",
    "    - classify\n",
    "    - evaluate_performance\n",
    "    - split_data\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, parameters_file: str):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        training_parameters = json.load(open(parameters_file))\n",
    "\n",
    "        self.__model = model\n",
    "        self.__training_dataloader = self.create_train_dataloader()\n",
    "        # self.__preprocessor: [torch.nn.Module, None] = None\n",
    "        self.__device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        self.lr = training_parameters['lr']\n",
    "        self.epochs = training_parameters['epochs']\n",
    "        self.MAX_EPOCHS = training_parameters['MAX_EPOCHS']\n",
    "\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def create_train_dataloader():\n",
    "        mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "        X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "        X_t = torch.from_numpy(X).float().cuda()\n",
    "        Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "        return ((X_train, y_train))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy(output, target):\n",
    "        logits = output[torch.arange(len(output)), target]\n",
    "        loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Method to train a model given a dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__model.train()\n",
    "        images, gts = self.__training_dataloader\n",
    "        images.to(self.__device)\n",
    "        gts.to(self.__device)\n",
    "\n",
    "        # x = self._preprocess(x)\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_batch = 10\n",
    "\n",
    "        for epoch in range(1, self.epochs+1):  \n",
    "\n",
    "            y_pred = self.__model(images)\n",
    "\n",
    "            # Gradiends are turned to zero in order to avoid acumulation\n",
    "            self.__model.zero_grad()\n",
    "\n",
    "            # loss\n",
    "            train_loss = self.cross_entropy(y_pred, gts)\n",
    "            epoch_loss.append(train_loss.item())\n",
    "\n",
    "            # Backprop\n",
    "            train_loss.backward()\n",
    "\n",
    "            # # updates\n",
    "            with torch.no_grad():\n",
    "                for param in self.__model.parameters():\n",
    "                    param -= self.lr * param.grad\n",
    "\n",
    "            # running_loss += train_loss.item()\n",
    "\n",
    "            # # loss logger\n",
    "            # self.log_metric(\"train_loss\", train_loss)\n",
    "\n",
    "            if not epoch % epoch_batch:\n",
    "                print(f\"Epoch {epoch}/{self.epochs} Loss {np.mean(epoch_loss):.5f}\") \n",
    "\n",
    "            if epoch >= self.MAX_EPOCHS:\n",
    "                break\n",
    "\n",
    "        return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test function split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(x_data, y_data, test_percent=0.20, seed=42):\n",
    "        \"\"\"\n",
    "        The method split_data(), which belongs to the class Model, receives four parameters:\n",
    "\n",
    "        - x_data: Samples (torch.Tensor).\n",
    "        - y_data: Targets of the samples (torch.Tensor).\n",
    "        - test_percent: Percentage of total data employed for testing (default = 0.20).\n",
    "        - seed:         Used to replicate the resulting training and evaluation sets (default = None).\n",
    "\n",
    "        And it is going to return two sets one for training and one for testing (each of which contains is divided into samples and targets).\n",
    "        \"\"\"\n",
    "\n",
    "        x_numpy = x_data.cpu().numpy()\n",
    "        y_numpy = y_data.cpu().numpy()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_percent, random_state=seed)\n",
    "        \n",
    "        return torch.from_numpy(X_train).float().cuda(), torch.from_numpy(X_test).float().cuda(), torch.from_numpy(y_train).long().cuda(), torch.from_numpy(y_test).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56000, 784])\n",
      "torch.Size([56000])\n",
      "torch.Size([14000, 784])\n",
      "torch.Size([14000])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_t = torch.from_numpy(X).float().cuda()\n",
    "Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_sample = 120\n",
    "\n",
    "print('Sample number: {}'.format(y_train[num_sample].cpu().numpy()))\n",
    "\n",
    "plt.imshow(X_train[num_sample].reshape((28,28)).cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test resizing images (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAALTklEQVR4nO3dT6il9X3H8fenJtkYoWOlwzAxNS3usjBFXEmxiwTrZsxG4mpCCjeLWtJdJFlECIEQ2nRZmBDJtKSGgFoHKU2shJhVcBSro5Jow0hmGGeQaYlZpdFvF/cZuY733nPn/Huee7/vFxzOOc898zzf+zCf+/s9v98555eqQtLB9wdjFyBpPQy71IRhl5ow7FIThl1q4kPrPFgSh/6lFauqbLd9oZY9yd1JfpHk9SQPLrIvSauVeefZk1wH/BL4NHAOeBa4v6pe2eXf2LJLK7aKlv0O4PWq+lVV/Q74AXBsgf1JWqFFwn4U+PWW5+eGbe+TZCPJ6SSnFziWpAWtfICuqk4AJ8BuvDSmRVr288DNW55/bNgmaYIWCfuzwK1JPpHkI8DngFPLKUvSss3dja+q3yd5APgRcB3wcFW9vLTKJC3V3FNvcx3Ma3Zp5VbyphpJ+4dhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNrPWrpNXPmAuHJtt++KstW3apCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasJ5du1qzHlyLZctu9SEYZeaMOxSE4ZdasKwS00YdqkJwy414Tz7Aec8ua5YKOxJzgJvA+8Av6+q25dRlKTlW0bL/pdV9dYS9iNphbxml5pYNOwF/DjJc0k2tntBko0kp5OcXvBYkhaQRQZwkhytqvNJ/hh4Cvjbqnpml9c7WrRmnQfoun7hZFVt+4sv1LJX1fnh/hLwOHDHIvuTtDpzhz3J9UluuPIY+AxwZlmFSVquRUbjDwOPD12lDwH/WlX/sZSqdE06d9W1dwtds1/zwbxmXwnDvj2v2d/PqTepCcMuNWHYpSYMu9SEYZea8COu+0DX0fauo+mrYssuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS004zz4BB3ke3bny6bBll5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmnGfXrpwnPzhs2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCefZ12DKn1d3Hr2PmS17koeTXEpyZsu2G5M8leS14f7QasuUtKi9dOO/B9x91bYHgaer6lbg6eG5pAmbGfaqega4fNXmY8DJ4fFJ4N7lliVp2ea9Zj9cVReGx28Ch3d6YZINYGPO40hakoUH6Kqqkuw4AlVVJ4ATALu9TtJqzTv1djHJEYDh/tLySpK0CvOG/RRwfHh8HHhiOeVIWpXMmgNO8ghwF3ATcBH4GvBvwA+BjwNvAPdV1dWDeNvtq2U3fsx59lXPo/segumpqm1/8ZlhXybDvn6GvZ+dwu7bZaUmDLvUhGGXmjDsUhOGXWrCj7guwZRHpGfZz7XPstvv1nGk3pZdasKwS00YdqkJwy41YdilJgy71IRhl5pwnv0A2G3O+CDPoy9iDx/tXlMl62PLLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNOM9+ADiXrr2wZZeaMOxSE4ZdasKwS00YdqkJwy41YdilJpxn12hmfWbc9w8s18yWPcnDSS4lObNl20NJzid5Ybjds9oyJS1qL9347wF3b7P9H6vqtuH278stS9KyzQx7VT0DXF5DLZJWaJEBugeSvDh08w/t9KIkG0lOJzm9wLEkLSh7GQRJcgvwZFV9cnh+GHgLKODrwJGq+sIe9nMgR1wcSJrPlAfo9vMXTlbVtsXP1bJX1cWqeqeq3gW+A9yxSHGSVm+usCc5suXpZ4EzO71W0jTMnGdP8ghwF3BTknPA14C7ktzGZjf+LPDF1ZWoMY3ZnZ1yN38/2tM1+9IO5jX7vjPla9dVnvcp/96zLPWaXdL+Y9ilJgy71IRhl5ow7FITfsS1uf086rxKB3FJZ1t2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCefYDbj/OB19xkD9NOAZbdqkJwy41YdilJgy71IRhl5ow7FIThl1qwnn2JZjyVx4veuxVztNPeR59P78/YSe27FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhPPs2tWU58J1bWa27EluTvKTJK8keTnJl4btNyZ5Kslrw/2h1ZcraV4z12dPcgQ4UlXPJ7kBeA64F/g8cLmqvpnkQeBQVX15xr5aNhO2jvvPfn4H3dzrs1fVhap6fnj8NvAqcBQ4BpwcXnaSzT8Akibqmq7Zk9wCfAr4OXC4qi4MP3oTOLzDv9kANhaoUdISzOzGv/fC5KPAT4FvVNVjSf63qv5wy8//p6p2vW63G6/9omU3HiDJh4FHge9X1WPD5ovD9fyV6/pLyyhU0mrsZTQ+wHeBV6vq21t+dAo4Pjw+Djyx/PIOhiS73qR12Mto/J3Az4CXgHeHzV9h87r9h8DHgTeA+6rq8ox92Z/dht386dnPf4R36sbv+Zp9GQz79gz79BzEsPt2WakJwy41YdilJgy71IRhl5rwI64TMOWvoj6o9vNo+7xs2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCefZ94GOc8JaPlt2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdamIv67PfnOQnSV5J8nKSLw3bH0pyPskLw+2e1ZcraV57WZ/9CHCkqp5PcgPwHHAvcB/w26r6+z0fzCWbpZXbacnmmd9UU1UXgAvD47eTvAocXW55klbtmq7Zk9wCfAr4+bDpgSQvJnk4yaEd/s1GktNJTi9WqqRFzOzGv/fC5KPAT4FvVNVjSQ4DbwEFfJ3Nrv4XZuzDbry0Yjt14/cU9iQfBp4EflRV397m57cAT1bVJ2fsx7BLK7ZT2PcyGh/gu8CrW4M+DNxd8VngzKJFSlqdvYzG3wn8DHgJeHfY/BXgfuA2NrvxZ4EvDoN5u+3Lll1asYW68cti2KXVm7sbL+lgMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjUx8wsnl+wt4I0tz28atk3RVGubal1gbfNaZm1/stMP1vp59g8cPDldVbePVsAuplrbVOsCa5vXumqzGy81YdilJsYO+4mRj7+bqdY21brA2ua1ltpGvWaXtD5jt+yS1sSwS02MEvYkdyf5RZLXkzw4Rg07SXI2yUvDMtSjrk83rKF3KcmZLdtuTPJUkteG+23X2Buptkks473LMuOjnruxlz9f+zV7kuuAXwKfBs4BzwL3V9Uray1kB0nOArdX1ehvwEjyF8BvgX++srRWkm8Bl6vqm8MfykNV9eWJ1PYQ17iM94pq22mZ8c8z4rlb5vLn8xijZb8DeL2qflVVvwN+ABwboY7Jq6pngMtXbT4GnBwen2TzP8va7VDbJFTVhap6fnj8NnBlmfFRz90uda3FGGE/Cvx6y/NzTGu99wJ+nOS5JBtjF7ONw1uW2XoTODxmMduYuYz3Ol21zPhkzt08y58vygG6D7qzqv4c+Cvgb4bu6iTV5jXYlOZO/wn4MzbXALwA/MOYxQzLjD8K/F1V/Wbrz8Y8d9vUtZbzNkbYzwM3b3n+sWHbJFTV+eH+EvA4m5cdU3Lxygq6w/2lket5T1VdrKp3qupd4DuMeO6GZcYfBb5fVY8Nm0c/d9vVta7zNkbYnwVuTfKJJB8BPgecGqGOD0hy/TBwQpLrgc8wvaWoTwHHh8fHgSdGrOV9prKM907LjDPyuRt9+fOqWvsNuIfNEfn/Br46Rg071PWnwH8Nt5fHrg14hM1u3f+xObbx18AfAU8DrwH/Cdw4odr+hc2lvV9kM1hHRqrtTja76C8CLwy3e8Y+d7vUtZbz5ttlpSYcoJOaMOxSE4ZdasKwS00YdqkJwy41YdilJv4f37Tc8BA+Mz0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stacked_img = np.stack((X_train.cpu().numpy(),) * 3, axis=-1)\n",
    "plt.imshow(stacked_img[num_sample].reshape((28,28,3)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test function get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_data, y_data):\n",
    "        \"\"\"\n",
    "        This method receives a set of samples (x_data), with their respective targets (y_data), and gets the accuracy of the model.\n",
    "        \"\"\"\n",
    "\n",
    "        num_correct = 0\n",
    "        num_samples = len(y_data)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_sample, y_sample in zip(x_data, y_data):\n",
    "                \n",
    "                scores = model(x_sample)\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == y_sample).sum()\n",
    "            \n",
    "            return (num_correct/num_samples)*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in, H, D_out = 784, 100, 10\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 31.7624,   3.0775,  21.7556, -28.7571,   0.1901,  -5.1070,  13.5286,\n",
       "          1.2703,  -3.5361,   9.5145], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[num_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training = Training(model, 'parameters.json')\n",
    "new_training.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulation __training_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def __training_dataloader():\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "    X_t = torch.from_numpy(X).float().cuda()\n",
    "    Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "    return ((X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test funcion training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "    \"\"\"\n",
    "    Method to train a model given a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    self.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in self.__training_dataloader:\n",
    "        images, gts = data\n",
    "\n",
    "        images.to(self.__device)\n",
    "        gts.to(self.__device)\n",
    "\n",
    "        # x = self._preprocess(x)\n",
    "\n",
    "        # preds = self(images)\n",
    "\n",
    "        # # ponemos a cero los gradientes\n",
    "        # self.zero_grad()\n",
    "\n",
    "        # # loss\n",
    "        # train_loss = self.criterion(preds, gts)\n",
    "        # train_loss.backward()\n",
    "\n",
    "        # # updates\n",
    "        # self.optimizer.step()\n",
    "\n",
    "        # running_loss += train_loss.item()\n",
    "\n",
    "        # # loss logger\n",
    "        # self.log_metric(\"train_loss\", train_loss)\n",
    "\n",
    "    return (images.shape, gts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training = Training(model, 'parameters.json')\n",
    "new_training.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Loss 14.47456\n",
      "Epoch 20/100 Loss 11.31852\n",
      "Epoch 30/100 Loss 9.45172\n",
      "Epoch 40/100 Loss 8.20859\n",
      "Epoch 50/100 Loss 7.31508\n",
      "Epoch 60/100 Loss 6.63780\n",
      "Epoch 70/100 Loss 6.10433\n",
      "Epoch 80/100 Loss 5.67161\n",
      "Epoch 90/100 Loss 5.31241\n",
      "Epoch 100/100 Loss 5.00867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707c54fc449c242a99d0015019b0ebb80e91ba051eefcf42ec4fa5bd006a7811"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hello_environments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
