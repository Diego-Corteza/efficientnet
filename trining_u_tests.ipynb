{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from typing import List, Dict, Tuple, Callable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\n",
    "    \"\"\"\n",
    "    The class 'train_model', which inherits from the class 'Model', is initialized with a dictionary that contains some parameters for the training:\n",
    "\n",
    "    - lr:         Learning rate (default = 0.001).\n",
    "    - epochs:     Number of epochs to train (default = 100).\n",
    "    - MAX_EPOCHS: Max number of epochs allowed (default = 1000).\n",
    "\n",
    "    And contains six methods:\n",
    "\n",
    "    - train\n",
    "    - classify\n",
    "    - evaluate_performance\n",
    "    - split_data\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, parameters_file: str):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        training_parameters = json.load(open(parameters_file))\n",
    "\n",
    "        self.__model = model\n",
    "        self.__training_dataloader = self.create_train_dataloader()\n",
    "        # self.__preprocessor: [torch.nn.Module, None] = None\n",
    "        self.__device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        self.lr = training_parameters['lr']\n",
    "        self.epochs = training_parameters['epochs']\n",
    "        self.MAX_EPOCHS = training_parameters['MAX_EPOCHS']\n",
    "\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def create_train_dataloader():\n",
    "        mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "        X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "        X_t = torch.from_numpy(X).float().cuda()\n",
    "        Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "        return ((X_train, y_train))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy(output, target):\n",
    "        logits = output[torch.arange(len(output)), target]\n",
    "        loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Method to train a model given a dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__model.train()\n",
    "        images, gts = self.__training_dataloader\n",
    "        images.to(self.__device)\n",
    "        gts.to(self.__device)\n",
    "\n",
    "        # x = self._preprocess(x)\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_batch = 10\n",
    "\n",
    "        for epoch in range(1, self.epochs+1):  \n",
    "\n",
    "            y_pred = self.__model(images)\n",
    "\n",
    "            # Gradiends are turned to zero in order to avoid acumulation\n",
    "            self.__model.zero_grad()\n",
    "\n",
    "            # loss\n",
    "            train_loss = self.cross_entropy(y_pred, gts)\n",
    "            epoch_loss.append(train_loss.item())\n",
    "\n",
    "            # Backprop\n",
    "            train_loss.backward()\n",
    "\n",
    "            # # updates\n",
    "            with torch.no_grad():\n",
    "                for param in self.__model.parameters():\n",
    "                    param -= self.lr * param.grad\n",
    "\n",
    "            # running_loss += train_loss.item()\n",
    "\n",
    "            # # loss logger\n",
    "            # self.log_metric(\"train_loss\", train_loss)\n",
    "\n",
    "            if not epoch % epoch_batch:\n",
    "                print(f\"Epoch {epoch}/{self.epochs} Loss {np.mean(epoch_loss):.5f}\") \n",
    "\n",
    "            if epoch >= self.MAX_EPOCHS:\n",
    "                break\n",
    "\n",
    "        return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test function split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(x_data, y_data, test_percent=0.20, seed=42):\n",
    "        \"\"\"\n",
    "        The method split_data(), which belongs to the class Model, receives four parameters:\n",
    "\n",
    "        - x_data: Samples (torch.Tensor).\n",
    "        - y_data: Targets of the samples (torch.Tensor).\n",
    "        - test_percent: Percentage of total data employed for testing (default = 0.20).\n",
    "        - seed:         Used to replicate the resulting training and evaluation sets (default = None).\n",
    "\n",
    "        And it is going to return two sets one for training and one for testing (each of which contains is divided into samples and targets).\n",
    "        \"\"\"\n",
    "\n",
    "        x_numpy = x_data.cpu().numpy()\n",
    "        y_numpy = y_data.cpu().numpy()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_numpy, y_numpy, test_size=test_percent, random_state=seed)\n",
    "        \n",
    "        return torch.from_numpy(X_train).float().cuda(), torch.from_numpy(X_test).float().cuda(), torch.from_numpy(y_train).long().cuda(), torch.from_numpy(y_test).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/franz/Desktop/EfficientNet Project/efficientnet/trining_u_tests.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000005?line=2'>3</a>\u001b[0m mnist \u001b[39m=\u001b[39m fetch_openml(\u001b[39m'\u001b[39m\u001b[39mmnist_784\u001b[39m\u001b[39m'\u001b[39m, version\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, as_frame\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000005?line=3'>4</a>\u001b[0m X, Y \u001b[39m=\u001b[39m mnist[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m], mnist[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000005?line=5'>6</a>\u001b[0m X_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(X)\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000005?line=6'>7</a>\u001b[0m Y_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(Y\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/franz/Desktop/EfficientNet%20Project/efficientnet/trining_u_tests.ipynb#ch0000005?line=8'>9</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m split_data(X_t, Y_t)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X_t = torch.from_numpy(X).float().cuda()\n",
    "Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_sample = 450\n",
    "\n",
    "print('Sample number: {}'.format(y_train[num_sample].cpu().numpy()))\n",
    "\n",
    "plt.imshow(X_train[num_sample].reshape((28,28)).cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test resizing images (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_img = np.stack((X_train.cpu().numpy(),) * 3, axis=-1)\n",
    "plt.imshow(stacked_img[num_sample].reshape((28,28,3)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test function get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_data, y_data):\n",
    "        \"\"\"\n",
    "        This method receives a set of samples (x_data), with their respective targets (y_data), and gets the accuracy of the model.\n",
    "        \"\"\"\n",
    "\n",
    "        num_correct = 0\n",
    "        num_samples = len(y_data)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_sample, y_sample in zip(x_data, y_data):\n",
    "                \n",
    "                scores = model(x_sample)\n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct += (predictions == y_sample).sum()\n",
    "            \n",
    "            return (num_correct/num_samples)*100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in, H, D_out = 784, 100, 10\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 31.7624,   3.0775,  21.7556, -28.7571,   0.1901,  -5.1070,  13.5286,\n",
       "          1.2703,  -3.5361,   9.5145], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[num_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training = Training(model, 'parameters.json')\n",
    "new_training.epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulation __training_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def __training_dataloader():\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    X, Y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "    X_t = torch.from_numpy(X).float().cuda()\n",
    "    Y_t = torch.from_numpy(Y.astype(int)).long().cuda()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X_t, Y_t)\n",
    "    return ((X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test funcion training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self):\n",
    "    \"\"\"\n",
    "    Method to train a model given a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    self.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in self.__training_dataloader:\n",
    "        images, gts = data\n",
    "\n",
    "        images.to(self.__device)\n",
    "        gts.to(self.__device)\n",
    "\n",
    "        # x = self._preprocess(x)\n",
    "\n",
    "        # preds = self(images)\n",
    "\n",
    "        # # ponemos a cero los gradientes\n",
    "        # self.zero_grad()\n",
    "\n",
    "        # # loss\n",
    "        # train_loss = self.criterion(preds, gts)\n",
    "        # train_loss.backward()\n",
    "\n",
    "        # # updates\n",
    "        # self.optimizer.step()\n",
    "\n",
    "        # running_loss += train_loss.item()\n",
    "\n",
    "        # # loss logger\n",
    "        # self.log_metric(\"train_loss\", train_loss)\n",
    "\n",
    "    return (images.shape, gts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training = Training(model, 'parameters.json')\n",
    "new_training.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Loss 14.47456\n",
      "Epoch 20/100 Loss 11.31852\n",
      "Epoch 30/100 Loss 9.45172\n",
      "Epoch 40/100 Loss 8.20859\n",
      "Epoch 50/100 Loss 7.31508\n",
      "Epoch 60/100 Loss 6.63780\n",
      "Epoch 70/100 Loss 6.10433\n",
      "Epoch 80/100 Loss 5.67161\n",
      "Epoch 90/100 Loss 5.31241\n",
      "Epoch 100/100 Loss 5.00867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707c54fc449c242a99d0015019b0ebb80e91ba051eefcf42ec4fa5bd006a7811"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hello_environments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
